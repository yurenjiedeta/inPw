合理管理爬虫的访问可以有效提升网站性能和SEO效果。

- 允许所有正规的爬虫
- 爬取延迟为10秒
- 只允许对SEO有影响的页面
- 可以考虑封禁一些第三方SEO分析的工具爬虫

```javascript
# 允许所有爬虫访问指定路径，并设置爬取延迟为10秒
User-agent: *
Disallow: /
Crawl-delay: 10

# 允许访问根目录
Allow: /$

# 允许访问/products路径，支持参数访问
Allow: /products$

# 允许访问/products/路径下的所有子路径
Allow: /products/

# 允许访问/page/custom/路径下的所有子路径
Allow: /page/custom/

# 允许访问/page/policy/路径下的所有子路径
Allow: /page/policy/

# 允许访问/robots.txt文件
Allow: /robots.txt

# 允许访问/favicon.ico文件
Allow: /favicon.ico

# 允许访问/search路径，支持参数访问
Allow: /search$

# 允许访问/sitemap.xml文件
Allow: /sitemap.xml

# 允许访问/categories路径
Allow: /categories

# 网站地图位置（相对路径）
Sitemap: /sitemap.xml
```